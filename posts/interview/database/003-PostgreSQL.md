---
title: "003-PostgreSQL.md"
date: 2025-12-29 16:54:27
tags: []
---
## 一、PostgreSQL 基础概念

### 1. PostgreSQL 是什么？适合什么场景？

PostgreSQL 是一个**功能完备、强调标准和扩展性的对象关系型数据库（ORDBMS）**，适合：
- 金融 / 政务系统
- 复杂查询 & 报表
- GIS / 时空数据
- AI / 数据平台

---

### 2. PostgreSQL 和 MySQL 的核心区别？

| 对比点    | PostgreSQL            | MySQL      |
|--------|-----------------------|------------|
| SQL 标准 | 更严格                   | 较宽松        |
| 事务     | 全面(仅内置 Postgres 存储引擎) | InnoDB 支持  |
| 扩展能力   | 极强                    | 一般         |
| JSON   | 原生支持                  | 有限         |
| 并发模型   | MVCC + 多版本            | MVCC（实现不同） |
| 隔离级别   | 默认RC                  | 默认RR       |
| 索引     |  B-Tree/Hash/GiST/SP-GiST/GIN/BRIN 索引                  |  B-Tree/Hash/ 全文索引       |

---

### 3. PostgreSQL 和 MySQL 的进程模型区别？

| 维度                 | PostgreSQL（PG）| MySQL                                                                 |
|----------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------|
| 核心进程 / 线程单元  | 多进程架构：<br>1. postmaster 主进程（父进程）；<br>2. 每个客户端连接对应一个独立的 postgres 子进程；<br>3. 系统级任务（如刷盘、清理）由独立的常驻核心进程（bgwriter、walwriter 等）处理。 | 单进程 + 多线程架构：<br>1. 仅 mysqld 一个主进程（守护进程）；<br>2. 所有功能（连接处理、系统任务）均在 mysqld 内通过线程实现；<br>3. 系统级任务（刷盘、复制）由 mysqld 内的后台线程处理。 |
| 进程 / 线程数量      | 进程数 = 1（postmaster） + N（核心进程） + M（连接数），数量随连接数线性增长 | 进程数 = 1（mysqld），线程数 = 核心后台线程数 + 连接处理线程数（线程池模式下线程数远小于连接数） |
| 内存模型             | 各进程共享 “全局共享内存”（Shared Buffer、WAL Buffer），但每个连接进程有独立的私有内存 | 所有线程共享 mysqld 进程的内存空间，连接线程有独立的私有内存（sort_buffer、join_buffer 等），核心资源（Buffer Pool）为全局共享 |

#### 1. 架构对高并发的影响
- **PG**：连接数越多，进程数线性增长，进程切换开销远大于线程，高并发（1000+连接）下性能下降明显，需依赖连接池（如 PgBouncer）复用连接；
- **MySQL**：单进程内多线程模型，线程池模式下可将线程数控制在核心数2-4倍，高并发下切换开销更低，原生支持高连接数场景。

#### 2. 内存管理差异
- **PG**：全局共享内存（Shared Buffer）为所有进程共享，但每个连接进程的私有内存（如 work_mem）独立分配，高连接下易出现内存碎片化；
- **MySQL**：Buffer Pool 全局共享且支持内存预分配/碎片整理，连接线程的私有内存可通过参数（如 sort_buffer_size）统一管控，内存利用率更高。

#### 3. 故障隔离性
- **PG**：单个连接进程崩溃（如 SQL 执行异常）不会影响主进程和其他连接，故障隔离性强；
- **MySQL**：线程崩溃可能导致整个 mysqld 进程异常（极端场景），需依赖主从/集群保障可用性，但故障恢复速度更快（线程重启 vs 进程重启）。
---

## 二、事务 & 并发（必考）

### 1. PostgreSQL 的事务隔离级别？

| 隔离级别           | 中文名称       | 核心特性（解决的问题）| 允许的异常                                   | 实现原理                                                                 |
|--------------------|----------------|---------------------------------------------|----------------------------------------------|--------------------------------------------------------------------------|
| READ UNCOMMITTED   | 读未提交       | 无（最低级别）| 脏读、不可重复读、幻读                       | PG 中无实际意义：即使配置该级别，PG 仍会降级为 READ COMMITTED（避免脏读，是 PG 的设计选择），无法读取未提交的数据。 |
| READ COMMITTED     | 读已提交（默认） | 避免脏读                                     | 不可重复读、幻读                             | 1. 每次查询都读取 “当前已提交的最新版本数据”；<br>2. 写操作仅锁定修改的行，读操作无锁（基于 MVCC 快照）。 |
| REPEATABLE READ    | 可重复读       | 避免脏读、不可重复读                         | 幻读（标准定义），但 PG 中几乎无幻读（通过快照隔离优化） | 1. 事务启动时创建全局快照，整个事务内所有查询都基于该快照读取数据，不受其他事务提交的影响；<br>2. 写操作会检测冲突，冲突则回滚事务。 |
| SERIALIZABLE       | 可串行化（最高级别） | 避免所有异常（脏读、不可重复读、幻读）| 无任何并发异常                               | 基于 “可串行化快照隔离（SSI）” 实现：<br>1. 事务启动时创建快照；<br>2. 运行时检测事务间的 “串行化冲突”；<br>3. 冲突则主动回滚其中一个事务，保证所有事务等价于串行执行。 |

#### 1. PG 隔离级别核心特点
- **READ UNCOMMITTED 降级逻辑**：PG 从设计上拒绝脏读，即使显式设置 `SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED`，实际仍以 READ COMMITTED 执行，是 PG 对数据一致性的底层保障；
- **REPEATABLE READ 弱化幻读**：不同于 MySQL 的 Gap Lock 解决幻读，PG 通过事务级全局快照，让同一事务内多次查询结果一致，仅在 “并发写入+范围查询” 极端场景可能出现理论幻读，实际业务中可忽略；
- **SERIALIZABLE 低性能损耗**：PG 的 SSI 机制无需强锁，通过冲突检测替代锁阻塞，相比传统串行化实现（全表锁），在中低并发下性能损耗仅 10%-20%。


---

### 2. PostgreSQL 的 MVCC 是如何实现的？

PostgreSQL（PG）的 MVCC（多版本并发控制）是其实现高并发读写分离、事务隔离级别的核心，本质是为每行数据维护多个版本，**读操作通过快照读取历史版本（无锁），写操作创建新版本（不阻塞读）**，彻底避免了 “读锁阻塞写、写锁阻塞读” 的问题

- 每行数据包含：
    - xmin（创建事务 ID）
    - xmax（删除事务 ID）
- 通过事务可见性规则判断数据版本

---

### 3. PostgreSQL 如何避免幻读？

PostgreSQL（PG）对 “幻读” 的规避能力远强于 MySQL，**核心通过MVCC 快照隔离增强 + 可串行化快照隔离（SSI） 实现** —— 不仅在 REPEATABLE READ 级别几乎消除幻读，还能在 SERIALIZABLE 级别实现绝对无幻读，彻底解决并发场景下的结果集不一致问题。

- Serializable 使用 **SSI（Serializable Snapshot Isolation）**
- 非加锁实现，性能优于传统 Serializable

---

### 4. PostgreSQL 会不会有回滚段？
**回滚段（Rollback Segment） 是数据库中用于存储事务修改数据前的 “旧版本数据” 的专用存储区域**，核心作用是支撑事务的回滚（ROLLBACK）、数据库的读一致性（MVCC），以及崩溃后的恢复（Crash Recovery）
# 三大数据库回滚/Undo 机制核心差异对比
| 数据库           | 回滚段 / Undo 机制                                                                 | 核心差异                                                                 |
|------------------|-------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| Oracle           | 显式的回滚段（Rollback Segment）：独立的磁盘段，存储事务的回滚数据                   | 回滚段是独立存储单元，可配置数量/大小，事务按需申请回滚段                 |
| MySQL InnoDB     | Undo 表空间（Undo Tablespace）：独立的文件，存储数据的旧版本（Undo Log）             | Undo 日志与数据分离，旧版本仅存于 Undo 表空间，表中只保留最新版本         |
| PostgreSQL       | **无独立回滚段** / Undo 表空间：旧版本数据直接存储在表本身（堆文件）中，事务回滚通过 “标记版本无效” 实现 | 旧版本与表数据同存储，无独立的 “回滚段” 概念，依赖 VACUUM 清理无效版本     |

#### 补充深度解读
#### 1. 存储架构差异（核心影响性能/维护）
| 维度         | Oracle                | MySQL InnoDB          | PostgreSQL            |
|--------------|-----------------------|-----------------------|-----------------------|
| 旧版本存储位置 | 独立回滚段（磁盘段）| 独立 Undo 表空间文件  | 表堆文件内（与数据同存） |
| 维护方式     | 手动配置回滚段数量/大小，需监控回滚段争用 | 自动管理 Undo 表空间，支持动态扩容/收缩 | 无独立维护单元，依赖 VACUUM 清理表内旧版本 |
| 空间回收     | 事务提交后回滚段空间可复用，需手动收缩 | Undo 日志过期后自动 purge，空间复用 | 需 VACUUM 标记旧版本空间可复用，VACUUM FULL 才释放给系统 |

#### 2. 对 MVCC 的支撑逻辑
- **Oracle**：通过回滚段存储事务修改前的原始数据，MVCC 读取时从回滚段获取历史版本，事务提交后回滚段数据可被覆盖；
- **MySQL InnoDB**：Undo 表空间存储数据旧版本，MVCC 基于 Undo Log 构建快照读，Undo 日志由 purge 线程异步清理；
- **PostgreSQL**：表内直接存储多版本数据，MVCC 读取时通过事务 ID（XID）判断版本可见性，旧版本需 VACUUM 清理，否则表持续膨胀。

#### 3. 运维核心差异
- **Oracle**：重点监控回滚段争用（如 `v$rollstat`），避免事务等待回滚段，需根据并发量调整回滚段数量；
- **MySQL InnoDB**：关注 Undo 表空间大小（`innodb_undo_tablespaces`），配置自动 purge 策略（`innodb_purge_threads`），避免 Undo 日志堆积；
- **PostgreSQL**：无需维护回滚段/Undo 表空间，但必须保障 VACUUM 正常执行（自动/手动），否则表膨胀、XID 溢出风险极高。

#### 4. 故障影响差异
- **Oracle**：回滚段损坏会导致依赖该段的事务无法回滚，需通过备份恢复回滚段；
- **MySQL InnoDB**：Undo 表空间损坏会导致数据一致性异常，需重建 Undo 表空间或恢复备份；
- **PostgreSQL**：无独立回滚/Undo 存储，表损坏直接影响数据本身，需通过 VACUUM 修复表碎片，严重时需重建表。

---

## 三、VACUUM & 存储管理（PG 特色）

### 1. 什么是 VACUUM？为什么重要？

#### PostgreSQL VACUUM 全解析：原理、作用与实战运维
VACUUM 是 PostgreSQL（PG）支撑 MVCC 机制正常运行的核心维护命令（含手动执行 + 自动 autovacuum），负责清理无效数据版本、维护事务 ID（XID）健康——**无 VACUUM 则 PG 会因数据膨胀、XID 溢出逐步性能劣化甚至崩溃**，是 PG 运维的“必修课”。

#### 一、核心问题：VACUUM 解决什么？
PG 的 MVCC 为实现“读写分离、无锁读”，更新/删除操作不会立即物理删除旧数据版本：
- **DELETE**：仅标记行版本的 `xmax`（删除事务 ID），不物理删除；
- **UPDATE**：本质是“删除旧版本 + 插入新版本”，旧版本仍留存。

这些未物理删除的“无效版本（死元组/死行）”会引发三大致命问题：
1. **表体积无限制膨胀**：删除 90% 数据后表文件大小仍不变，磁盘空间完全浪费；
2. **XID 回卷风险**：32 位 XID 溢出后，PG 无法判断数据可见性，数据库直接崩溃；
3. **查询性能暴跌**：扫描表时需遍历大量无效版本，IO/CPU 开销剧增。

#### 二、VACUUM 核心定义与分类
#### 1. 基本定义
VACUUM 是 PG 内置命令，扫描表/索引清理无效版本、更新统计信息、冻结旧 XID，分为两种核心模式：

| 模式           | 核心特点                                                                 | 适用场景                                   |
|----------------|--------------------------------------------------------------------------|--------------------------------------------|
| 普通 VACUUM    | 非阻塞（可与读写并行），仅标记无效空间为“可复用”（不释放给操作系统）| 日常维护、低峰期轻量清理（核心推荐）|
| VACUUM FULL    | 阻塞（独占表锁），重建表并释放磁盘空间给操作系统                         | 表膨胀严重、急需回收磁盘（需业务低峰期执行）|

#### 2. 执行方式：自动 vs 手动
- **自动清理（autovacuum）**：PG 默认开启（`autovacuum = on`），由后台进程根据“死元组比例/数量”自动触发，无需人工干预；
- **手动 VACUUM**：自动清理不及时（如长事务阻塞）时，执行 `VACUUM [TABLE_NAME]` 或 `VACUUM FULL [TABLE_NAME]`。

#### 三、VACUUM 核心作用（为什么是运维基石？）
#### 1. **清理死元组** —— 解决表膨胀
VACUUM 扫描表后：
- 普通 VACUUM：标记死元组空间为“可复用”（后续插入可直接使用，无需新增磁盘空间）；
- VACUUM FULL：物理删除死元组并释放空间给操作系统（但会独占表锁，业务不可写）。

**不清理的后果**：表体积翻倍/十倍增长，查询需遍历大量无效数据，索引也会堆积无效条目。

#### 2. 冻结旧 XID（Freeze XID）—— 避免数据库崩溃
PG 的 32 位 XID 存在回卷风险，VACUUM（尤其是 `VACUUM FREEZE`）会将表中旧版本的 `xmin/xmax` 替换为 `FrozenXID`（固定值 2，永久可见），冻结后的 XID 不再参与计数，从根本上避免溢出。

> 临界阈值：PG 会在 XID 接近 20 亿时强制触发 `VACUUM FREEZE`，若仍无法完成，数据库会进入**只读模式**保护自身。

#### 3. 更新统计信息 —— 优化查询计划
VACUUM 自动更新 `pg_statistic` 系统表的统计信息（行数、字段值分布、死元组比例），优化器依赖这些信息生成最优执行计划。

**统计信息过期的后果**：优化器可能选择“全表扫描”而非“索引扫描”，查询性能暴跌。

#### 4. 清理索引无效条目 —— 维护索引健康
PG 索引（B-Tree/GIN/GiST）会为每行版本创建条目，数据版本失效后索引条目也会无效：
- VACUUM 清理索引无效条目，减少索引体积；
- 对 GIN/GiST 等复杂索引，还会优化结构提升扫描效率。

#### 四、实战运维建议
#### 1. 日常维护（核心）
- 依赖 autovacuum：确保 `autovacuum = on`，调整阈值（如 `autovacuum_vacuum_threshold = 50` + `autovacuum_vacuum_scale_factor = 0.1`），避免死元组堆积；
- 低峰期手动 VACUUM：对大表（千万级以上）执行 `VACUUM ANALYZE table_name;`（ANALYZE 强制更新统计信息）。

#### 2. 表膨胀应急处理
- 优先用 `VACUUM` 而非 `VACUUM FULL`：若必须释放空间，可先创建新表迁移数据，再切换表名（避免独占锁）；
- 监控膨胀率：通过 `pg_stat_user_tables` 查看 `n_dead_tup`（死元组数量），膨胀率 > 50% 时及时清理。

#### 3. 避坑点
- 禁止在业务高峰期执行 `VACUUM FULL`：会阻塞所有读写，导致业务不可用；
- 长事务会阻塞 autovacuum：需控制事务时长（避免超过 1 小时），及时提交/回滚。

---

### 2. autovacuum 是什么？

- 自动执行 VACUUM
- 后台守护进程
- 防止事务 ID 回卷（wraparound）

---

### 3. VACUUM 和 VACUUM FULL 区别？

| 类型 | 区别 |
|----|----|
| VACUUM | 不锁表，空间不返还 OS |
| VACUUM FULL | 重写表，强锁表 |

---

## 四、索引机制（高频）

### 1. PostgreSQL 支持哪些索引类型？
| 索引类型   | 核心特性                                                                 | 适用场景                                                                 | 平均查询性能       | 写入性能影响       |
|------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|--------------------|--------------------|
| B-Tree     | 最基础，支持等值/范围查询、排序，PG 默认索引                             | 主键、外键、等值/范围查询（如 `WHERE id=1`、`WHERE create_time > '2024-01-01'`） | 最优（O (log n)）| 低（写入时仅维护树结构） |
| Hash       | 仅支持等值查询，不支持范围/排序                                         | 高频等值查询（如 `WHERE name='张三'`），PG 10+ 已弱化（B-Tree 等值性能接近） | 优（O (1)）| 中（哈希冲突会影响性能） |
| GiST       | 通用搜索树，支持多维数据、非等值查询                                     | 地理空间（GIS）、全文检索、区间查询、相似度查询                           | 中 - 优            | 中 - 高（写入时需维护复杂结构） |
| SP-GiST    | 空间分区 GiST，优化非平衡数据结构                                       | 四叉树、k-d 树场景（如地理位置分区、电话号码前缀查询）| 优（针对分区数据）| 中                 |
| GIN        | 倒排索引，支持多值类型（数组、JSONB）| 全文检索、数组包含查询、JSONB 键值查询（如 `WHERE tags @> '{postgres}'`） | 优（多值匹配）| 高（写入时构建倒排表） |
| BRIN       | 块范围索引，针对有序大数据集                                             | 时序数据、日志表、分区表（如亿级行的时间字段索引）| 中（仅适合有序数据） | 极低（仅记录块范围统计） |
| Bloom      | 布隆过滤器索引（扩展插件）| 多列低频等值查询（如 `WHERE a=1 AND b=2 AND c=3`）| 中                 | 低                 |


---

### 2. PostgreSQL 支持函数索引吗？

- 支持
- 常用于大小写不敏感查询

> PostgreSQL 完全支持函数索引（Functional Index），且函数索引是 PG 优化复杂查询的核心特性之一 —— 它允许基于 “函数 / 表达式的计算结果” 创建索引，而非直接基于字段值，能大幅提升包含函数 / 表达式的查询性能。
---

### 3. PostgreSQL 的索引是聚簇索引吗？

- **不是**
- 表和索引物理分离
- 可使用 `CLUSTER` 重排

---

## 五、SQL & 查询优化

### 1. PostgreSQL 如何查看执行计划？
```sql
EXPLAIN [选项] SQL语句;
```
| 选项组合             | 核心作用                                                                 | 适用场景                                                                 | 关键注意事项                                                         |
|----------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------|
| EXPLAIN              | 仅展示**预估**执行计划，不实际执行 SQL                                   | 快速梳理 SQL 执行逻辑（如 JOIN 顺序、是否走索引），适配 DELETE/UPDATE 等写操作 | 仅为优化器预估结果，行数/耗时与实际可能偏差较大                       |
| EXPLAIN ANALYZE      | 执行 SQL 并展示**真实**执行计划（含耗时、扫描行数、循环次数）| 精准定位慢查询性能瓶颈（如全表扫描、排序耗时过长）| 会实际执行 SQL，写操作需包裹在 `BEGIN/ROLLBACK` 中避免数据变更        |
| EXPLAIN VERBOSE       | 展示更详细的执行计划（字段列表、函数调用、表别名、关联条件）| 排查索引不生效、字段匹配错误、表别名冲突等细节问题                       | 建议结合基础 EXPLAIN/ANALYZE 使用，单独使用价值有限                   |
| EXPLAIN BUFFERS      | 展示内存/磁盘缓冲使用情况（物理读、逻辑读、共享块命中数）| 定位 IO 瓶颈（如物理读占比高→数据未缓存/索引失效）| 必须搭配 `ANALYZE` 使用（`EXPLAIN ANALYZE BUFFERS`），否则无缓冲数据  |
| EXPLAIN COSTS        | 展示优化器成本估算（启动成本、总执行成本、行数、字段宽度）| 分析优化器选择执行计划的逻辑（为何走全表而非索引）| 默认开启，可通过 `EXPLAIN (COSTS OFF)` 关闭                          |
| EXPLAIN TIMING       | 展示执行计划中每个步骤的**实际耗时**（毫秒级）| 定位执行计划中耗时最长的单个步骤（如排序、哈希关联）| 必须搭配 `ANALYZE` 使用，高并发场景慎用（会增加 SQL 执行耗时）|


### 2. PostgreSQL 的查询优化器特点？

- 成本优化器（CBO）

- 基于统计信息

- 支持并行查询

| 维度               | PostgreSQL                          | MySQL（InnoDB）|
|--------------------|-------------------------------------|---------------------------------------------|
| 优化器类型         | 纯 CBO（成本驱动）| 混合 CBO+RBO（规则驱动为主，如优先走主键索引） |
| JOIN 顺序优化      | 支持多表 JOIN 全顺序枚举（剪枝优化） | 仅支持有限的 JOIN 顺序（如左深树），大表 JOIN 易选差顺序 |
| 统计信息粒度       | 字段级直方图 + 唯一值统计，粒度细   | 表级 / 索引级统计，粒度粗（MySQL 8.0 提升）|
| 并行查询           | 支持并行扫描 / 聚合 / 连接          | 仅支持并行扫描（MySQL 8.0）|
| 索引选择           | 基于选择性动态判断（有索引也可能不用） | 规则驱动（有索引优先用，易选低效索引）|
| 复杂查询优化       | 深度优化 CTE / 窗口函数 / 子查询    | 对复杂子查询优化较弱（易产生临时表）|


### 3. PostgreSQL 并行查询什么时候生效？
> PostgreSQL 的并行查询（Parallel Query）是提升大表查询性能的核心特性（PG 9.6 首次引入，后续版本持续增强），其生效有严格的触发条件和配置限制—— 并非所有查询都能并行执行，**核心是优化器判断 “并行执行的成本低于串行执行”**

- **基础条件**：SELECT 查询 + 未禁用并行 + 无并行不兼容操作；
- **成本条件**：优化器判断并行成本 < 串行成本（**大表易满足**，小表反之）；
- **配置条件**：max_parallel_workers_per_gather > 0 + 合理的并行成本 / 大小阈值；

### 4. PostgreSQL 如何处理 JSON？

| 特性           | JSON 类型                                  | JSONB 类型                                  |
|----------------|--------------------------------------------|---------------------------------------------|
| 存储形式       | **纯文本**（保留原始格式，含空格/注释）| **二进制解析格式**（无冗余，可直接操作）|
| 写入性能       | 快（无需解析）| 稍慢（需解析并转换为二进制）|
| 查询/修改性能  | 慢（每次查询需重新解析）| 快（直接操作二进制结构）|
| 索引支持       | 不支持                                     | 支持 GIN/GiST/函数索引                      |
| 重复键处理     | 保留所有重复键（如 {"a":1,"a":2}）| 仅保留最后一个重复键                        |
| 空格/顺序保留  | 保留原始空格和键顺序                       | 不保留空格，键顺序无序（哈希存储）|
| 适用场景       | 日志存储、原始数据归档（需保留格式）| 高频查询、更新、需索引的业务场景            |

> 99% 的业务场景优先选择 JSONB—— 除非需要严格保留 JSON 原始格式（如日志审计、第三方数据同步），否则 JSONB 的查询性能和索引支持是不可替代的

## 六、锁机制（面试常问）
### 1. PostgreSQL 有哪些锁？

| 分类维度   | 具体类型                          | 核心说明                                                                 | 实战关联要点                                                                 |
|------------|-----------------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| 锁粒度     | **表锁、行锁、页锁**、函数锁、扩展锁等 | 粒度越小，并发越高（行锁 > 页锁 > 表锁），但加锁/解锁开销越大             | 1. 高频写场景优先行锁（如 UPDATE WHERE id=?）；<br>2. 批量操作慎用表锁（阻塞全表读写） |
| 锁模式     | 共享锁（S）、排他锁（X）、共享更新锁（SU）等 | 控制 “读/写” 冲突：<br>- S 锁：允许多事务并发读，阻塞写；<br>- X 锁：独占读写，阻塞所有冲突操作；<br>- SU 锁：介于 S/X 之间，支持共享读+有限更新 | 1. 读操作默认加 S 锁（SELECT）；<br>2. 写操作加 X 锁（INSERT/UPDATE/DELETE）；<br>3. SU 锁适配 “读为主、偶更新” 场景 |
| 锁策略     | 悲观锁（显式加锁）、乐观锁（版本/时间戳） | - 悲观锁：先加锁再操作，阻塞冲突（如 SELECT ... FOR UPDATE）；<br>- 乐观锁：无锁操作，冲突后重试（如 WHERE version = ?） | 1. 高并发写用乐观锁（减少阻塞）；<br>2. 低并发/数据一致性要求高用悲观锁（如金融交易） |
| 自动/手动  | 自动锁（SQL 隐式加锁）、手动锁（LOCK TABLE/FOR UPDATE） | 大部分场景依赖自动锁，特殊场景需手动加锁控制粒度/时机                     | 1. 普通 CRUD 依赖自动锁，无需干预；<br>2. 跨表事务需手动加表锁（LOCK TABLE t1, t2 IN EXCLUSIVE MODE） |



### 2. PostgreSQL 如何查看锁？

- **基础监控**：用 pg_locks + pg_stat_activity 查看所有锁，识别 granted=false 的等待进程；
- **定位阻塞**：通过关联查询找到 blocking_pid（阻塞源），查看其执行的 SQL；
- **检测死锁**：实时查询双向阻塞进程，或查看日志中的 deadlock detected；
- **解决问题**：终止阻塞源进程，或优化业务逻辑（如缩短事务、统一加锁顺序）。

### 3. PostgreSQL 如何处理死锁？

- 自动检测

- 主动回滚一个事务

---

## 七、高级特性（PG 加分项）
### 1. PostgreSQL 支持逻辑复制吗？
> PostgreSQL **完全支持逻辑复制**（Logical Replication），逻辑复制是一种**基于「数据行的逻辑变更**（如 INSERT/UPDATE/DELETE）」的复制方式，b，它能精准复制指定表 / 指定数据的变更，且支持跨 PostgreSQL 版本、跨平台（甚至跨数据库）的复制，是 PostgreSQL 10 + 引入的核心特性（10 之前需依赖触发器 / 第三方工具）。
> 
> 简单来说：**逻辑复制的核心是 “捕获数据的逻辑变更（如‘插入 id=1,name = 张三’），而非复制数据的物理存储”**，因此更灵活、更精准，适配精细化的数据同步场景

| 特性           | 逻辑复制                                  | 物理复制（流复制）|
|----------------|-------------------------------------------|---------------------------------------------|
| 复制粒度       | 表级 / 行级（可指定表、列、过滤条件）| 实例级（整库复制，无法筛选）|
| 数据格式       | 基于 SQL 逻辑日志（如 INSERT/UPDATE 语句） | 基于磁盘块的物理日志（WAL）|
| 跨版本支持     | 支持（如 PG 12 → PG 16）| 仅主从大版本一致（如 PG 14 → PG 14）|
| 跨数据库类型   | 可对接外部系统（如 Kafka、MySQL）| 仅 PG 实例间                                |
| 复制方向       | 支持多主复制、双向复制                    | 仅主从单向复制                              |
| 资源开销       | 较高（需解析 WAL 为逻辑日志）| 较低（直接复制物理块）|
| 适用场景       | 增量同步、分库分表、跨版本升级、数据订阅   | 高可用、灾备、读写分离                      |

#### PostgreSQL 的原生逻辑复制是灵活、细粒度的数据同步方案，核心优势：
- 支持表级 / 行级 / 列级复制，适配精准同步场景；
- 跨版本、跨集群复制，兼容第三方系统；
- 支持多主复制、双向复制，满足复杂业务架构；

使用要点：
- 发布端需配置 wal_level = logical，并合理设置复制槽和 WAL 保留策略；
- 手动保证订阅端表结构与发布端一致，且表有主键 / 唯一键；
- 定期监控复制槽状态，避免 WAL 日志堆积导致磁盘满；
- 高并发场景下，建议拆分多个发布 / 订阅，分散复制压力。

逻辑复制是 PG 超越传统关系型数据库的核心特性之一，是实现 “数据中台、跨库同步、高可用架构” 的关键工具。


### 2. PostgreSQL 支持分区表吗？

- 原生支持（Range / List / Hash）
- 查询自动路由

| 分区类型       | 拆分规则                                                                 | 适用场景                                   | 示例                                                         |
|----------------|--------------------------------------------------------------------------|--------------------------------------------|--------------------------------------------------------------|
| 范围分区（RANGE） | 按数值 / 时间范围拆分（如 ID 1-1000、时间 2024-01 至 2024-02）| 时间序列数据、主键范围数据                 | 订单表按 create_time 按月分区，用户表按 id 按 100 万段分区   |
| 列表分区（LIST）  | 按离散值列表拆分（如地区 = 华东 / 华北 / 华南、状态 = 已支付 / 已取消）| 固定分类数据                               | 订单表按 region（地区）分区，用户表按 status（状态）分区     |
| 哈希分区（HASH）  | 按字段哈希值取模拆分（如 id % 4 = 0/1/2/3）| 均匀分散数据、负载均衡                     | 高并发写入的流水表，按 user_id 哈希分区，分散写入压力         |
| 复合分区       | 多层分区（如先按时间范围，再按地区列表）| 多维度筛选的复杂业务数据                   | 订单表先按 create_time 按季度范围分区，再按 region 列表分区   |

### 3. PostgreSQL 的 JSONB 和 ES 有何区别？

PG：事务强、结构化

ES：全文搜索、近实时

| 维度       | PostgreSQL JSONB                | Elasticsearch                          |
|------------|---------------------------------|----------------------------------------|
| 本质       | 关系型数据库的字段类型，兼顾事务与半结构化存储 | 分布式检索引擎，专注全文检索与聚合分析 |
| 优势       | 事务、JOIN、数据完整性、精准查询、低维护成本 | 全文检索、分布式扩展、聚合分析、实时性、可视化 |
| 劣势       | 全文检索能力弱、海量数据性能差、无分布式能力 | 无事务、无 JOIN、数据完整性弱、维护成本高 |

### 4. PostgreSQL 为什么适合做数据平台？

- **全能性**：覆盖结构化 / 非结构化 / 时序 / 空间数据的存储和计算，无需多系统拼接；
- **扩展性**：通过扩展可补齐分布式、列存、AI 分析等能力，适配数据平台的规模增长；
- **可靠性**：ACID 事务 + 高可用保障数据准确性，符合企业级数据平台的核心诉求；

 | 方案                | 核心劣势                                  | PostgreSQL 的优势                          |
  |---------------------|-------------------------------------------|-------------------------------------------|
  | MySQL               | JSON 支持弱、分区表能力有限、OLAP 性能差   | 全类型数据支持、强 OLAP 能力、丰富扩展     |
  | Hive/Spark SQL      | 无事务、查询延迟高、小数据量查询性能差     | ACID 事务、毫秒级查询、兼顾小数据和大数据 |
  | ClickHouse          | 事务支持弱、JOIN 性能差、生态兼容性低      | 完整事务、强 JOIN 能力、兼容主流 BI/ETL 工具 |
  | Elasticsearch       | 无事务、无 JOIN、数据完整性弱              | ACID 事务、强 JOIN、数据约束保证准确性     |
  | 商业数据库（Oracle）| 成本高、开源生态弱、云适配差               | 开源免费、生态丰富、云原生适配好           |