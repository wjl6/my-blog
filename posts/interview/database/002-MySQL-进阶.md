---
title: "002-MySQL-进阶.md"
date: 2025-12-26 14:41:29
tags: []
---

## 一、MySQL 大数据量场景

### 1. 你理解的“大数据量”是多少？

通常经验划分：
- **百万级**：索引 + SQL 优化即可
- **千万级**：需要分库分表 / 归档
- **亿级以上**：分布式方案 + 异步化

👉 面试回答要点：  
**数据量不是绝对值，而是“是否影响业务响应时间”**

#### 核心结论
###### 1. “大数据量” 是相对概念，无绝对数值
脱离硬件、表结构、业务场景谈数据量没有意义，示例：
- 低配服务器（机械硬盘 + 16GB 内存）：百万级行就可能成为大数据量，引发性能问题；
- 高配服务器（SSD + 256GB 内存 + 多核 CPU）：亿级行的优化表（合理索引、分区）仍可稳定运行。

###### 2. 性能拐点是核心判断标准
当出现以下特征时，无论数据量多少，均可判定为 “大数据量”，需立即优化：
- 常规查询耗时从毫秒级飙升至秒级；
- 插入/更新操作频繁阻塞（锁竞争、I/O 瓶颈）；
- 索引失效，优化器默认选择全表扫描；
- 服务器资源（CPU/内存/磁盘 I/O）持续高负载（利用率 > 80%）。

###### 3. 预防大于治理：提前规划优于事后优化
在系统设计初期，需预判数据增长趋势，通过以下策略规避性能拐点：
- **分区表**：按时间/地域等维度拆分数据（如按月份分区存储订单）；
- **分库分表**：高并发核心表（如用户订单）提前做水平/垂直拆分；
- **冷热分离**：将历史冷数据归档至低成本存储，热数据保留在高性能库；
- **索引规划**：根据业务查询场景设计最优索引，避免冗余/无效索引。

---

### 2. 大表会带来哪些问题？

常见问题：
- 查询变慢（索引失效）
- B+Tree（索引） 过深
- DDL 锁表时间长，更易造成死锁
- 运维风险增加
- 备份、迁移成本高

---

### 3. 千万级表如何优化查询？

常见手段：
1. **合理索引**
    - 联合索引
    - 覆盖索引
2. **SQL 优化**
    - 避免 select *
    - 避免函数 / 隐式转换
3. **内存 / 缓存优化**（调大缓冲池 + 热点缓存）
4. **分区表**
5. **读写分离 / 分库分表**

---

### 4. 什么情况下索引会失效？

#### MySQL 索引失效场景全解析（附修复方案+验证方法）
| 失效场景分类                | 典型示例（索引字段：idx_col）                                                                 | 失效核心原因                                  | 修复方案                                                                 | 验证方法（EXPLAIN 关键指标）                          |
|-----------------------------|-----------------------------------------------------------------------------------------------|-----------------------------------------------|--------------------------------------------------------------------------|-------------------------------------------------------|
| **索引字段函数 / 表达式运算**   | `SELECT * FROM t WHERE ROUND(price)=100`<br>`SELECT * FROM t WHERE DATE(create_time)='2024-01-01'` | B + 树存储原始值，函数运算后值与索引不匹配    | 1. 运算移到等号右侧：`price BETWEEN 99.5 AND 100.5`<br>2. 时间范围替换函数：`create_time BETWEEN '2024-01-01 00:00:00' AND '2024-01-01 23:59:59'` | type 从 ALL → range；Extra 无 Using filesort          |
| **隐式类型转换**                | `SELECT * FROM t WHERE id='100'`（id 是 INT）<br>`SELECT * FROM t WHERE phone=13800138000`（phone 是 VARCHAR） | 类型转换破坏索引有序性                        | 保证查询值与字段类型一致：<br>`id=100`<br>`phone='13800138000'`          | type 从 ALL → ref；key 显示目标索引名                 |
| **联合索引违反最左匹配原则**    | 联合索引 idx_a_b(a,b)，查询 `SELECT * FROM t WHERE b=2`                                       | 联合索引按最左字段排序，跳过左侧字段无法定位  | 1. 补充最左前缀字段：`WHERE a=1 AND b=2`<br>2. 单独为 b 建索引（低优先级） | type 从 ALL → ref；key 显示 idx_a_b                   |
| **非等值查询**（!=/NOT IN）     | `SELECT * FROM t WHERE status!=1`<br>`SELECT * FROM t WHERE id NOT IN (1,2,3)`                 | 否定式查询无法利用 B + 树有序性              | 1. 替换为范围查询：`status<1 OR status>1`<br>2. 数据量小时保留，业务层过滤 | type 从 ALL → range；rows 扫描行数减少                |
| **左模糊匹配（LIKE '%xxx'）**   | `SELECT * FROM t WHERE name LIKE '%手机'`                                                     | 左模糊无法匹配索引前缀，无法定位起始位置      | 1. 改为右模糊：`LIKE '手机%'`（业务允许时）<br>2. 长文本用全文索引：`MATCH(name) AGAINST('手机')` | type 从 ALL → range（右模糊）/ fulltext（全文索引）   |
| **OR 连接无索引字段**           | `SELECT * FROM t WHERE id=100 OR name='手机'`（id 有索引，name 无）                            | OR 一侧无索引时，扫描索引+全表成本高于直接全表扫描 | 1. 给 name 建索引<br>2. 拆分为 UNION ALL：<br>`SELECT * FROM t WHERE id=100 UNION ALL SELECT * FROM t WHERE name='手机'` | type 从 ALL → ref；key 显示对应索引                   |
| **IS NULL/IS NOT NULL（无索引）** | `SELECT * FROM t WHERE category IS NULL`（category 无索引）                                    | 无索引时需全表扫描；IS NOT NULL 遍历所有非空值 | 1. 给 category 建索引<br>2. 用默认值替代 NULL：`category=0`               | type 从 ALL → ref；rows 扫描行数骤降                  |
| **索引选择性差**                | `SELECT * FROM t WHERE status=1`（status 只有 0/1，占比 90%）                                  | 索引选择性过低，走索引不如全表快              | 1. 组合高选择性字段：`status=1 AND create_time>'2024-01-01'`<br>2. 强制走索引（慎用）：`FORCE INDEX(idx_status)` | type 从 ALL → ref；Extra 显示 Using index condition   |
| **JOIN 关联字段类型 / 编码不一致** | `SELECT * FROM a JOIN b ON a.user_id = b.id`（a.user_id 是 INT，b.id 是 VARCHAR）               | 类型/编码不一致触发隐式转换，关联索引失效     | 1. 统一字段类型：`ALTER TABLE b MODIFY id INT`<br>2. 显式转换：`a.user_id = CAST(b.id AS UNSIGNED)` | type 从 ALL → ref；Extra 无 Using join buffer         |
| **统计信息过期**                | 长期未更新统计信息，`SELECT * FROM t WHERE idx_col=1` 走全表扫描                              | 优化器依赖过期统计信息，误判索引效率          | 更新统计信息：`ANALYZE TABLE t;`                                         | type 从 ALL → ref；rows 预估行数接近实际              |

---

### 5. explain 中需要重点关注哪些字段？

| 字段名          | 核心作用                                                                 | 关键判断标准                                                                 | 异常 / 优化方向                                                                 |
|-----------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| **type**            | 表示 MySQL 查找数据的方式（访问类型），最核心的性能指标                   | 优先级：system > const > eq_ref > ref > range > index > ALL<br>✅ 理想值：ref/range（千万级表）、eq_ref（主键/唯一索引等值查询）<br>❌ 最差值：ALL（全表扫描，索引失效） | 出现 ALL 时，优先检查索引是否失效；<br>出现 index（全索引扫描）时，需优化索引覆盖度 |
| **key**             | 实际使用的索引名（NULL 表示未走索引）| ✅ 非 NULL，且与预期索引名一致<br>❌ NULL（索引失效）| NULL 时，排查索引失效场景（函数运算、最左匹配等）；<br>非预期索引时，检查是否需用 FORCE INDEX 强制索引 |
| **rows**            | MySQL 预估需要扫描的行数（越接近实际行数越优）| ✅ 数值越小越好（千万级表需控制在 1000 以内）<br>❌ 数值接近表总行数（全表扫描） | 数值过大时，优化索引或查询条件，减少扫描范围；<br>预估行数与实际差距大时，执行 ANALYZE TABLE 更新统计信息 |
| **Extra**           | 额外执行信息（包含索引使用、排序、临时表等关键细节）| ✅ 理想值：Using index（覆盖索引，无回表）、Using where（仅扫描符合条件的行）<br>❌ 危险值：Using filesort（文件排序）、Using temporary（临时表）、Using join buffer（连接缓冲） | 1. Using filesort：优化排序字段的索引（如建联合索引包含排序字段）；<br>2. Using temporary：避免 GROUP BY 非索引字段，或优化分组逻辑；<br>3. Using join buffer：给 JOIN 关联字段建索引 |
| possible_keys   | 可能用到的索引列表（供优化器选择）| ✅ 包含预期索引<br>❌ 空（无可用索引）| 空时，需为查询条件字段建索引；<br>非空但 key 为 NULL 时，优化器认为走索引不如全表快（如索引选择性差） |
| ref             | 与索引比较的列 / 常量（显示索引关联的字段）| ✅ 非 NULL（如 const、users.id）<br>❌ NULL（无关联，全表 / 全索引扫描） | NULL 时，检查索引是否为等值 / 范围查询，是否违反最左匹配 |
| id              | 查询执行的优先级（子查询 / 联合查询的执行顺序）| ✅ 数值相同：按从上到下执行；<br>数值不同：值越大优先级越高 | 复杂查询中，id 多表示子查询嵌套深，可拆分查询减少嵌套 |
| key_len         | 使用的索引长度（字节数，越短越优）| ✅ 与实际索引字段长度匹配（无冗余）<br>❌ 过长（包含不必要的索引字段） | 过长时，优化联合索引（移除非必要字段），减少索引存储开销 |
| Extra 补充      | 索引条件下推（ICP），仅扫描索引中符合条件的行                             | ✅ 出现该值（减少回表次数）| 未出现时，检查 MySQL 版本（5.6 + 支持），或查询条件是否可下推 |

---

### 6. MySQL存在深度分页吗？该如何解决？
MySQL 同样**存在深度分页问题**，且在数据量较大（百万级以上）、分页页码过深（如第 1000 页、第 10000 页）时，性能下降会非常明显，甚至出现查询超时。

1. 深度分页的典型表现  
   MySQL 最常用的分页语法是 LIMIT offset, size（offset 为偏移量，即跳过前 N 条数据；size 为每页显示条数），深度分页的问题集中体现在：
```sql
-- 浅分页：offset 较小，查询耗时 < 10ms
SELECT id, name, age FROM user ORDER BY id LIMIT 100, 20;

-- 深度分页：offset 极大，查询耗时 > 1000ms（甚至更久）
SELECT id, name, age FROM user ORDER BY id LIMIT 1000000, 20;
```
2. 核心成因（为什么 offset 过大会变慢？）
- MySQL 执行 **LIMIT offset, size 的底层逻辑是「全量扫描→跳过→截取」**，这是深度分页性能问题的根源，具体流程如下：
  - 全量扫描并排序：MySQL 会根据 ORDER BY 后的字段（若未索引）进行全表扫描，或通过索引扫描获取符合条件的数据，然后按照指定规则排序；
  - 跳过前 offset 条数据：MySQL 不会直接定位到 offset 对应的位置，而是会先扫描并加载前 offset + size 条数据到内存中；
  - 截取并返回 size 条数据：从加载的 offset + size 条数据中，跳过前 offset 条，只截取后面 size 条数据返回给客户端。

#### MySQL 深度分页的 4 种核心解决方案（从优到劣）
**方案 1：基于「主键 / 唯一索引」的锚点分页（最优解，推荐生产环境使用）**  

这是解决 MySQL 深度分页性能问题的「黄金方案」，原理与 ES 的 Search After 一致，核心是「用上一页最后一条数据的主键 / 唯一索引值作为查询条件，替代 offset 偏移量」，避免全量扫描前 offset 条数据。
- 实现原理
  - 依赖「主键（如 id）」或「唯一索引字段（如 user_no）」的有序性（主键默认自增，天然有序；唯一索引也保证有序）；
  - 首次查询（第 1 页）使用普通分页，记录下最后一条数据的主键值；
  - 后续分页（第 N 页）通过 WHERE 主键 > 上一页最后一个主键值 定位数据，再配合 LIMIT size 截取每页数据，无需使用 offset。

**方案 2：优化索引，减少「文件排序」（辅助优化，配合其他方案）**   

如果业务场景无法使用锚点分页（必须支持随机跳转到第 N 页），可通过「优化索引」来缓解深度分页的性能问题，核心是「让 MySQL 利用索引完成排序，避免触发文件排序（filesort）」。
- 实现原理
  - 为 ORDER BY 后的字段创建单独索引，或创建「查询字段 + 排序字段」的复合索引；
  - 利用 MySQL 索引的有序性，直接通过索引获取排序后的数据，无需额外扫描全表并排序，减少磁盘 IO 和内存开销。

**方案 3：子查询 / 联表查询，先定位主键再查询数据（优化 LIMIT offset, size）**  

该方案的核心思想是「拆分查询，先通过索引快速定位到 offset 对应的主键，再通过主键查询完整数据」，避免直接扫描大量非主键数据，本质是减少无效数据的加载和排序。
- 实现原理
  - 第一步（子查询 / 联表）：仅查询主键字段，利用索引快速获取 offset 对应的主键值（主键索引体积小，扫描速度快）；
  - 第二步：通过获取到的主键值，查询完整的业务数据，此时 LIMIT 仅用于截取少量数据，无性能压力。

**方案 4：限制最大分页页码，避免极端深度分页（业务层面优化）**

这是一种「从业务源头规避问题」的方案，核心是通过业务限制，避免用户触发极端深度分页，从而从根本上杜绝深度分页的性能问题。
- 实现方式
  - 限制分页的最大页码（如最多支持查询前 1000 页），当用户尝试访问超过 1000 页时，返回提示「页码过大，请缩小查询范围」；
  - 提供「高级筛选」功能，引导用户通过条件筛选（如按时间、按分类）减少数据总量，避免翻到过深页码；
  - 前端分页器隐藏「跳转到指定页码」的输入框，仅保留「上一页 / 下一页 / 首页 / 尾页」，且尾页限制为最大允许页码。

#### 总结
| 解决方案                 | 核心优势                                     | 核心局限                                     | 适用场景                                           |
|--------------------------|----------------------------------------------|----------------------------------------------|----------------------------------------------------|
| 锚点分页（主键 / 唯一索引） | 性能极致、无性能瓶颈、资源消耗小             | 不支持随机分页，仅支持连续翻页               | 百万级大数据表、前端下拉加载、核心业务分页         |
| 优化索引（避免文件排序） | 支持随机分页、改造成本低、无需修改语法       | 仅缓解性能问题，超大 offset 仍有瓶颈         | 后台管理系统、中等深度分页、需随机跳转页码         |
| 子查询 / 联表查询        | 支持随机分页、性能优于原生 LIMIT             | 依赖主键排序、超大 offset 性能有限           | 中等深度分页、排序字段为主键、无法使用锚点分页     |
| 业务层面限制最大页码     | 从根源规避问题、实现简单、无数据库压力       | 灵活性受限，不支持全量浏览                   | 前台业务、无需极端深度分页、引导用户筛选           |

---

## 二、大表设计与拆分

### 1. 什么是分库分表？什么时候需要？

- **分表**：单表数据量过大
- **分库**：并发压力大 / 连接数不足

触发条件：
- 单表 > 千万
- QPS 高
- DDL 难以维护

---

### 2. 常见分表策略？

#### MySQL 分表策略全维度对比（核心逻辑+场景+优缺点+工具）
| 分表类型   | 细分策略   | 核心逻辑                                                                 | 适用场景                                           | 典型实现工具               | 优点                                                                 | 缺点                                                                 |
|------------|------------|--------------------------------------------------------------------------|----------------------------------------------------|----------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|
| 垂直分表   | 按字段拆分 | 将大表的字段拆分为多个小表（核心字段 + 扩展字段分离）                     | 单表字段过多（如含 TEXT/BLOB）、读写字段分离       | 原生 SQL（无需中间件）| 1. 减少单表字段数，提升查询/写入速度；<br>2. 降低行大小，减少磁盘 IO 和内存占用；<br>3. 大字段拆分后主表性能提升显著；<br>4. 实现简单，无需中间件 | 1. 联表查询需 JOIN（可通过应用层两次查询规避）；<br>2. 需保证主从表数据一致性（事务/触发器）；<br>3. 业务代码需适配多表查询逻辑 |
| 水平分表   | 范围分表   | 按 ID / 时间等连续值范围拆分（如 ID 1-100 万为表 1，101-200 万为表 2）| 数据有明显范围特征（订单 / 日志按时间，用户 ID 按段） | Sharding-JDBC、MyCat       | 1. 拆分规则简单，易理解和维护；<br>2. 历史数据可单独归档/删除，不影响核心表；<br>3. 扩容简单（新增范围表即可）；<br>4. 范围查询（如查某月订单）性能优 | 1. 数据热点集中（如最新时间的表读写压力大）；<br>2. 跨范围查询需联合多表；<br>3. ID/时间分布不均时，部分表数据量仍过大 |
| 水平分表   | 哈希分表   | 按 ID 哈希取模拆分（如 ID%100=0→表 0，ID%100=1→表 1）| 数据分布均匀、无明显范围特征（用户表、商品表）| Sharding-JDBC、MyCat       | 1. 数据分布均匀，无热点表；<br>2. 单表数据量可控（总数据量/表数）；<br>3. 高并发下性能稳定；<br>4. 等值查询（如按 ID 查用户）路由精准 | 1. 拆分规则固定，扩容困难（扩表需迁移数据）；<br>2. 跨表查询（如按 name 查询）需遍历所有子表；<br>3. 依赖分布式 ID，自增主键易冲突 |
| 水平分表   | 列表分表   | 按业务维度枚举拆分（如按省份：北京→表 1，上海→表 2）| 数据可按固定业务维度划分（地域、业务线）| Sharding-JDBC、MyCat       | 1. 业务关联性强，查询时可快速定位子表；<br>2. 数据按业务隔离，便于权限控制；<br>3. 无需复杂路由算法，易实现 | 1. 业务维度值过多时，表数量爆炸，维护成本高；<br>2. 部分维度数据量不均（如北京表远大于西藏表）；<br>3. 新增维度需新增表，适配业务代码 |
| 混合分表   | 范围 + 哈希 | 先按时间范围拆分，再按 ID 哈希拆分                                       | 超大规模数据（如日志表：按年月分库，再按 ID 哈希分表） | Sharding-JDBC              | 1. 兼顾范围查询和数据均匀分布，性能最优；<br>2. 扩容灵活（先扩表，再扩库）；<br>3. 可分散热点，支持超大规模数据 | 1. 实现复杂，需中间件支持；<br>2. 维护成本高，需监控所有分库分表；<br>3. 跨范围+跨哈希查询复杂度极高 |

---

### 3. 分库分表后如何查询？

方案：
- 中间件（ShardingSphere）
- 业务聚合 union all
- 避免跨库 join

---

### 4. 分表后主键如何设计？

#### MySQL 分表场景分布式主键方案全对比
| 方案类型               | 核心逻辑                                                                 | 实现方式                                                                 | 适用场景                                  | 优点                                                                 | 缺点                                                                 |
|------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|-------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|
| 分布式 ID（雪花算法）| 64 位长整型 ID，包含：时间戳（41 位）+ 机器 ID（10 位）+ 序列号（12 位） | 1. 自研生成器（Java/C++）；<br>2. 中间件（如 Leaf、UidGenerator）；<br>3. 数据库中间件（Sharding-JDBC 内置） | 所有分表场景（哈希/范围/混合分表），高并发（TPS 10 万+） | 1. 全局唯一，有序递增（时间戳维度）；<br>2. 无单点瓶颈（分布式生成）；<br>3. 适配所有分表策略；<br>4. 64 位整型，索引性能优 | 1. 依赖时钟（时钟回拨可能导致重复）；<br>2. 实现略复杂（需部署生成器/中间件）；<br>3. 无业务语义 |
| 分段自增主键（号段模式） | 从统一号段服务获取「起始值 + 步长」（如 1-1000），各分表在段内自增       | 1. 中间件（Leaf-segment、美团分布式 ID）；<br>2. 数据库表存储号段（如 id_generator 表） | 范围分表/混合分表，中等并发（TPS 1 万-10 万） | 1. 有序递增，适配范围分表；<br>2. 生成效率高（本地缓存号段）；<br>3. 可自定义步长适配分表数 | 1. 依赖号段服务（单点风险，需高可用）；<br>2. 号段耗尽需重新获取（可能短暂阻塞）；<br>3. 哈希分表需额外适配 |
| 复合主键（分表标识+自增） | 主键 = 分表标识（如表序号） + 分表内自增 ID（如：001_10001）             | 1. 字符串拼接（如 VARCHAR：concat(表序号, '_', AUTO_INCREMENT)）；<br>2. 数值拼接（如 BIGINT：表序号*1000000 + 自增ID） | 简单分表（列表分表/小规模哈希分表），低并发 | 1. 实现简单，无需中间件；<br>2. 主键包含分表标识，路由更直观 | 1. 字符串主键索引性能差；<br>2. 数值拼接易出现位数溢出；<br>3. 全局有序性差；<br>4. 分表数扩容需调整拼接规则 |
| UUID/GUID              | 32 位字符串唯一标识（基于机器码 + 时间 + 随机数）                        | 1. MySQL 函数：UUID()；<br>2. 编程语言生成（如 Java：UUID.randomUUID ()） | 无性能要求的场景（如日志表），临时数据     | 1. 实现极简单，无依赖；<br>2. 全局唯一，无需协调 | 1. 字符串类型，索引性能极差（B + 树分裂频繁）；<br>2. 无序，写入性能低；<br>3. 占用空间大（36 字符 vs 8 字节长整型） |
| 数据库自增主键 + 库表偏移 | 各分表自增主键起始值不同（如表 1：1-100 万，表 2：101 万-200 万）| 1. 建表时指定 AUTO_INCREMENT：CREATE TABLE t1 (id INT AUTO_INCREMENT PRIMARY KEY) AUTO_INCREMENT=1;；<br>2. 表 2：AUTO_INCREMENT=1000001; | 小规模范围分表（分表数≤10），低并发       | 1. 完全复用 MySQL 自增逻辑，适配成本低；<br>2. 有序，索引性能优 | 1. 扩容困难（新增表需计算起始值，易冲突）；<br>2. 分表数受限（起始值易耗尽）；<br>3. 仅适配范围分表 |
---

## 三、MySQL 高并发写入场景

### 1. 高并发写入 MySQL 的瓶颈？

| 瓶颈类型         | 核心成因                                                                 | 典型表现                                                                 | 优化优先级 | 核心优化方案                                                         |
|------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|------------|----------------------------------------------------------------------|
| **磁盘 IO 瓶颈**     | 写入需刷盘（redo log/binlog），机械硬盘 IOPS 不足；SSD 也有读写带宽上限   | 写入延迟 > 100ms；iostat 显示 % util 接近 100%；磁盘 IOPS 打满           | 最高       | 1. 换 SSD；2. 调优日志刷盘策略；3. 批量写入；4. 分离冷热数据         |
| **锁冲突瓶颈**       | 行锁竞争（热点行）、表锁 / MDL 锁阻塞、间隙锁扩大锁范围                   | 大量 Lock wait timeout；死锁频发；show processlist 大量 Waiting for lock  | 最高       | 1. 热点行拆分；2. 乐观锁替代悲观锁；3. 降级隔离级别；4. 避免长事务     |
| **日志刷盘瓶颈**     | redo log/binlog 同步刷盘（sync_binlog=1/innodb_flush_log_at_trx_commit=1） | 写入 TPS 上不去；事务提交耗时占比 > 80%                                  | 高         | 1. 调整刷盘策略（牺牲少量一致性）；2. 组提交（log_group_commits）；3. 加大日志缓存 |
| **索引维护瓶颈**     | 高频写入触发索引 B + 树分裂、页合并；索引过多导致写入时更新索引耗时       | 插入耗时随数据量增长飙升；show engine innodb status 有大量 page split     | 高         | 1. 减少冗余索引；2. 延迟创建索引；3. 选择有序主键（减少分裂）         |
| 事务 / 连接瓶颈  | 短事务未及时释放连接；连接池打满；大事务占用资源过久                     | Too many connections；事务执行时间 > 1s；连接池耗尽                      | 中         | 1. 优化为短事务；2. 调大连接池；3. 连接复用；4. 拆分大事务           |
| CPU / 内存瓶颈   | 写入时数据校验、索引计算、日志编码消耗 CPU；内存不足导致缓存失效          | top 显示 CPU 利用率 > 90%；内存 swap 频繁；innodb_buffer_pool 命中率低    | 中         | 1. 升级 CPU；2. 调大 innodb_buffer_pool；3. 关闭不必要的校验（如 binlog_checksum） |
| 主从同步瓶颈     | 大量 binlog 导致从库回放延迟；主库 binlog 写入阻塞                       | 从库延迟 > 分钟级；主库 show slave status 显示 Seconds_Behind_Master 飙升 | 中         | 1. 从库并行回放；2. 分库分表分散同步压力；3. 减少 binlog 量           |

---

### 2. 如何优化高并发写？

- 参数调优
- 批量写入
- 异步化（MQ）
- 减少事务粒度（降低事务隔离级别）
- 合理索引（避免过多索引）

#### 优化原则：先软后硬，先单机后架构
1. **低成本见效快（优先落地）**：参数调优、写入方式优化、锁优化解决逻辑瓶颈，无需架构改造，性价比最高；
2. **资源层优化（次之）**：索引精简、硬件升级解决物理资源瓶颈，成本中等，效果稳定；
3. **架构层突破（最后）**：分库分表、分布式数据库突破单机上限，仅用于超高性能需求。

#### 性能收益参考
- 常规优化（批量写入 + 日志刷盘调优 + 热点行拆分 + 有序主键）：单机写入 TPS 可提升至 1 万 - 5 万；
- 超高性能需求（10 万 + TPS）：需结合分库分表或分布式数据库（如 TiDB、OceanBase）。

---

### 3. 自增主键为什么会成为瓶颈？

自增主键的核心问题是：**MySQL 为保证自增 ID 的全局唯一性，对自增计数器的更新是 “串行化” 的（排他锁 / 互斥量），高并发下所有写入请求需排队等待 ID 分配，形成写入瓶颈**

原因：
- 自增锁
- 页分裂
> 底层机制
> - 自增主键是有序的，高并发插入时，所有新数据都会写入 InnoDB 聚簇索引的 “最后一页”（**热点页**），引发两个问题：
> - **页锁竞争**：多个写入请求同时修改热点页，需等待页级锁（latch），加剧延迟；
> - **页分裂频繁**：热点页写满后会触发页分裂，每次分裂需耗时 10-100ms，高并发下频繁分裂会导致写入性能暴跌。

解决方案：
- 业务 ID
- 雪花算法

核心原则：**自增主键仅适合低并发、单表、无扩容需求的场景；高并发 / 分布式场景下，优先选择分布式有序 ID**

---

## 四、数据迁移场景（重点）

### 1. 常见数据迁移场景有哪些？

- 单库 → 分库分表
- 老系统 → 新系统
- MySQL → MySQL（结构变化）
- 冷热数据迁移

---

### 2. 数据迁移的核心难点？

#### MySQL 分库分表数据迁移核心难点全解析
| 难点类型               | 核心成因                                                                 | 典型表现                                                                 | 影响级别 | 核心解决方案                                                         |
|------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|----------|----------------------------------------------------------------------|
| **数据一致性**             | 迁移过程中源库持续写入；增量数据同步延迟；数据类型 / 编码不兼容           | 目标库数据缺失、重复、不一致；业务查询结果错误                           | 最高     | 全量 + 增量双阶段迁移；全量数据校验（MD5/行数对比）；增量事务补偿机制 |
| **业务无感知**（零停机）| 迁移需保证业务读写不中断；新旧库切换需无缝衔接                           | 迁移期间业务报错、超时；切换时数据丢失                                   | 最高     | 新旧库双写 + 读写分流；灰度切换（按用户/流量比例）；流量快速回滚机制 |
| **高并发 / 大数据量性能瓶颈** | 全量迁移耗时过长；增量同步压力大；目标库写入瓶颈                         | 迁移周期超预期；源库 / 目标库 CPU/IO 打满                               | 高       | 分批次迁移（按ID/时间分片）；迁移限速限流；目标库预优化（索引延迟创建、刷盘策略调整） |
| 数据结构兼容性         | 源库与目标库字段类型、索引、约束不兼容；分表后路由规则复杂               | 数据插入失败；索引失效；约束冲突                                         | 高       | 提前做数据结构映射；适配目标库分表路由规则；迁移期间临时禁用非核心约束 |
| 迁移后验证             | 数据量巨大，全量校验成本高；隐性逻辑不一致（如函数计算结果不同）         | 迁移后发现数据错误，需回滚                                               | 中       | 全量数据校验（行数/哈希）+ 抽样校验（核心业务数据）；业务逻辑对比测试 |
| 回滚机制缺失           | 未规划回滚方案；增量数据同步不可逆                                       | 迁移失败后无法快速恢复业务                                               | 中       | 预留回滚窗口期（如7天）；全量备份源库；双写阶段保留回滚能力         |-

---

### 3. 大数据量如何迁移而不停机？

经典方案（必会）：

1. **全量迁移**
2. **增量同步**
3. **双写**
4. **切流量**

---

### 4. 如何做全量数据迁移？

方式：
- 分批分页迁移（limit + id）
- 离线工具（DataX）
- 控制批次大小，防止打爆 DB

---

### 5. 增量数据如何同步？

| 同步原理               | 核心机制                                                                 | 优点                                                                 | 缺点                                                                 | 适用场景                                           |
|------------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------|
| **基于 binlog（日志解析）** | 解析数据库的二进制日志（如 MySQL binlog），获取增量变更                   | 1. 实时性高（毫秒级）；<br>2. 无侵入（不修改业务/数据库逻辑）；<br>3. 覆盖所有 DML 操作 | 1. 需提前开启 binlog；<br>2. 依赖特定日志格式（如 Row 模式）；<br>3. 解析逻辑需适配版本 | MySQL/TiDB 等支持 binlog 的数据库（最主流）|
| 基于 CDC（变更数据捕获） | 基于数据库原生 CDC 能力（如 MySQL CDC、PostgreSQL WAL），流式捕获变更     | 1. 实时性更高（亚毫秒级）；<br>2. 支持多类型数据库；<br>3. 可流式处理（适配大数据框架） | 1. 部分数据库需开启专属配置；<br>2. 学习/部署成本高；<br>3. 需依赖 CDC 中间件（如 Flink CDC） | 跨库同步（如 MySQL→TiDB/ClickHouse）、大数据分析场景 |
| 基于轮询（定时查询）| 定时查询源库的增量字段（如 create_time/update_time），同步新增/变更数据   | 1. 实现极简单（SQL 即可）；<br>2. 无侵入；<br>3. 适配所有数据库         | 1. 实时性差（秒/分钟级）；<br>2. 定时查询占用源库资源；<br>3. 易漏查/重复查 | 低并发、非核心业务（如日志表、离线统计表）|
| 基于业务埋点（双写/MQ） | 业务代码写入源库时，同时发送变更消息到 MQ，消费端同步到目标库             | 1. 可控性高（可定制同步规则）；<br>2. 支持复杂业务逻辑；<br>3. 可作为兜底方案 | 1. 侵入业务代码；<br>2. 需处理消息一致性（幂等/重试）；<br>3. 代码改造成本高 | 高定制化场景、双写兜底同步、业务与数据同步强绑定的场景 |

#### 补充说明
增量同步的本质是 **“捕获源库的变更日志 → 解析日志 → 转换适配 → 写入目标库”**，四类原理的核心差异在于「变更日志的捕获方式」：
- binlog/CDC 属于「数据库层无侵入捕获」，是企业级同步的主流选择；
- 轮询/业务埋点属于「应用层主动捕获」，适配中小规模、低实时性需求场景。

---

### 6. 什么是“双写”？有什么风险？

双写：
- 指业务系统在写入数据时，**同时向两个（或多个）数据库（源库 + 目标库）执行相同的写入操作**

风险：
- 数据一致性风险（最高优先级）
- 性能损耗风险
- 业务逻辑异常风险
- 回滚复杂

---

### 7. 数据迁移如何保证一致性？

手段：
- 校验行数
- 校验 checksum
- 抽样比对

---

### 8. 数据迁移失败如何回滚？

- 保留旧库
- 切流量而非删数据
- 只读保护

---

## 五、线上改表（DDL）场景

### 1. MySQL 在线加字段会锁表吗？

| MySQL 版本   | 加字段是否锁表（InnoDB）| 核心机制                                                                 | 业务影响                                                                 |
|--------------|--------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| 5.5 及以下   | 是（全表排他锁）| 执行 ALTER 时持有表级排他锁，期间读写全阻塞                             | 业务完全不可用，直到操作完成（大表耗时极长，风险极高）|
| 5.6          | 部分场景锁表（默认）| 引入 Online DDL，但仅支持 “无默认值、可 NULL” 字段的在线添加；含默认值 / 非 NULL 仍锁表 | 简单字段（如 `ADD col INT NULL`）无写阻塞，复杂字段（含默认值/非NULL）仍全量阻塞 |
| 5.7+         | 几乎不锁表（MDL 短时锁）| 完善 Online DDL，仅在 ALTER 开始/结束时持有 MDL 读锁（毫秒级），期间写操作可正常执行；仅特殊场景触发重锁 | 业务无感知（大表仅耗时，无读写阻塞，可业务低峰期操作）|
| 8.0+         | **极致优化**（MDL 最小化）| 引入 MDL 锁升级优化，即使加含默认值的字段（如 `DEFAULT 'xxx'`）也无需全表更新，仅修改元数据 | 几乎无性能影响，大表也可安全操作（默认值字段添加仅修改表结构，无数据更新） |

> MDL（Metadata Lock）即元数据锁，是 MySQL 5.5 + 版本引入的核心锁机制，用于保护数据库对象的元数据（表结构、列、索引等）不被并发修改

#### 核心风险总览
5.7+ 虽通过 Online DDL 实现「几乎不锁表」，但以下非锁表类风险仍会引发业务异常，需重点规避：

##### 一、 MDL 锁等待风暴（最常见风险）
#### 成因
`ALTER TABLE` 需获取 MDL 排他锁，若当前有长事务（慢查询、未提交事务）持有该表的 MDL 读锁，ALTER 会排队等待；
排队期间，后续所有写操作（INSERT/UPDATE/DELETE）也会阻塞等待 MDL 锁，形成「锁等待链」，最终导致业务写入全面阻塞。

#### 规避方案
1. 操作前清理长事务：
   - 执行 `show processlist` 排查慢查询/未提交事务，kill 耗时超过阈值的事务；
   - 业务侧控制事务时长（避免超过 10s），关闭不必要的长连接未提交事务。
2. 缩短 MDL 锁持有时间：
   - 先执行 `ALTER TABLE tbl_name FORCE` 释放旧的 MDL 锁（无业务影响）；
   - 低峰期操作，且操作前暂停非核心业务的读写。

#### 二、 全表更新引发的 IO/CPU 压力
#### 成因
5.7 中新增 `NOT NULL` 或含 `DEFAULT` 的字段时，会全表扫描并填充默认值，亿级大表会触发 IO/CPU 打满，数据库性能断崖式下降。

#### 规避方案
1. 分阶段操作（核心方案）：
```sql
-- 步骤1：先加 NULL 字段（无需填充默认值，无全表更新）
ALTER TABLE t ADD col VARCHAR(20) NULL;
-- 步骤2：低峰期批量更新默认值（分批执行，避免单次压力过大）
UPDATE t SET col='default_val' WHERE col IS NULL LIMIT 1000; -- 循环执行
-- 步骤3：修改为 NOT NULL（仅改元数据，无全表扫描）
ALTER TABLE t MODIFY col VARCHAR(20) NOT NULL DEFAULT 'default_val';
```

---

### 2. 如何安全地在线改表？

常见方案：
- 优先升级到 MySQL 8.0+：极致优化默认值、MDL 锁，几乎无风险；
- pt-online-schema-change
- gh-ost
- 新表 + 数据迁移 + 切表

---

### 3. 为什么不建议在高峰期直接 alter 表？

- MDL 锁
- 阻塞写操作
- 可能导致雪崩

---

## 六、SQL 调优

### 1. 一条 SQL 很慢，你的排查思路是什么？

**标准排查流程（高分回答模板）**：

1. 是否命中索引
2. 使用 `EXPLAIN` 分析执行计划
3. 看扫描行数（rows）
4. 是否出现 filesort / temporary
5. 是否可以拆分 SQL 或改业务逻辑

👉 面试官要的是**方法论，不是一句“加索引”**

---

### 2. EXPLAIN 中常见 type 类型有哪些？哪个好？

从好到坏排序：

- const
- eq_ref
- ref
- range
- index
- all（全表扫描，最差）

---

### 3. 什么是覆盖索引？为什么快？

- 查询字段 **全部在索引中**
- 不需要回表
- IO 次数更少

---

### 4. 为什么 `select *` 是性能杀手？

- 无法使用覆盖索引
- 增加网络 IO
- 表结构变化风险高

---

### 5. 索引设计有哪些原则？

高频原则：
- 区分度高的字段
- 联合索引遵循最左前缀
- 查询条件驱动索引，而不是字段多就建

---

### 6. 联合索引什么时候会失效？

常见失效场景：
- 未使用最左前缀
- 范围查询后字段失效
- 隐式类型转换

---

### 7. like 查询如何优化？

- 避免 `%xxx`
- 使用 `xxx%`
- 或引入 ES

---

### 8. order by 一定会走索引吗？

不一定，条件包括：
- 顺序一致
- 字段一致
- 排序方向一致

否则会触发 `filesort`

---

### 9. 深度分页为什么慢？如何优化？

问题：
- `limit offset` 扫描大量无用数据

优化方案：
- 基于 ID 游标分页
- 记录最后一条 ID

---

### 10. count(*) 很慢怎么办？

优化思路：
- 使用近似统计
- Redis 计数
- 分表统计后聚合

---


### 11. MySQL 常见的性能优化手段？

#### SQL 层
- 避免在 where 条件中对字段做函数操作
- 合理使用索引（联合索引最左前缀）
- 避免 select *

#### 索引设计
- 高区分度字段建索引
- 业务查询驱动索引，而不是“字段多就建”

#### 架构层
- Redis 缓存热点数据
- 读写分离


---

### 12. 什么是间隙锁？为什么会死锁？

- 防止幻读
- 锁住范围而非记录
- 高并发下容易冲突

---

### 13. 如何减少锁冲突？

- 缩小事务范围
- 合理索引
- 避免长事务

---

## 七、真实场景题

### 1. 订单表数据量过亿，你怎么设计？

参考方案：
- 按时间分表
- 近 3 个月热数据
- 历史订单归档
- ES 提供查询

---

### 2. 日志表每天千万级写入，如何处理？

- 不直接写 MySQL
- MQ → 异步消费
- 定期落库 / 冷存储

---


### 3. MySQL 添加数据时，同时向MQ投递消息，如何保证数据一致性？
```java
@Transactional(rollbackFor = Exception.class)
public Long addProduct(Product product) {
    // 步骤1：插入数据库，返回自增主键ID
    productMapper.insert(product);
    Long id = product.getId(); // 数据库自增主键
    
    // 步骤2：生产MQ消息（包含主键ID），投递到MQ
    try {
        String msg = JSON.toJSONString(product);
        rabbitTemplate.convertAndSend("es_sync_topic", msg);
    } catch (Exception e) {
        // 步骤3：消息投递失败，回滚数据库
        throw new RuntimeException("消息投递失败，回滚数据库");
    }
    return id;
}
```
这段代码“看起来可行”，但实际上不成立
- 问题 1：convertAndSend ≠ 消息真的投递成功
- 问题 2：数据库事务 和 MQ 不在同一个事务里 ---❗ 分布式事务不一致问题（DB ↔ MQ）
- 问题 3：即便你捕获异常回滚，也仍然不可靠

解决方案：
- 本地消息表（最终一致性）
```text
1. 开启数据库事务
2. 插入业务表（product）
3. 插入消息表（message，状态=待发送）
4. 提交事务（DB 一定正确）
5. 后台任务/异步线程 扫描消息表
6. 发送 MQ
7. 成功 → 更新状态
8. 失败 → 重试（幂等）
```
























