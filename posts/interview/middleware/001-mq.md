---
title: "001-mq.md"
date: 2025-12-26 15:08:09
tags: []
---

### 1. 为什么要使用消息队列？

核心作用：
- **解耦系统**
- **异步处理**
- **削峰填谷**

典型场景：
- 下单后异步扣库存
- 发送短信 / 通知
- 秒杀 / 促销、 日志与数据分析

---

### 2. RabbitMQ 的核心组件？

- Producer（生产者）
- Exchange（交换机）
- Queue（队列）
- Binding（绑定）
- Consumer（消费者）

```text
生产者 → 连接(Connection)/信道(Channel) → 交换器(Exchange) → 绑定(Binding) → 队列(Queue) → 消费者
```

---

### 3. RabbitMQ 的交换机类型？

| 类型 | 路由规则 | 适用场景 |
|------|----------|----------|
| Direct | 消息的 Routing Key 与 绑定的 Binding Key 完全匹配，才会路由到队列 | 一对一消息传递（如订单通知） |
| Fanout | 忽略 Routing Key，将消息广播到所有绑定的队列 | 一对多消息传递（如广播通知） |
| Topic | 消息的 Routing Key 与 绑定的 Binding Key 模糊匹配（支持 */#） | 多维度消息路由（如按用户 / 地区路由） |
| Headers | 忽略 Routing Key，根据消息的 Header 属性 匹配路由 | 复杂属性匹配（极少使用） |

---

### 4. 如何保证消息不丢失？

从 **三个层面** 说明（高频）：

1. **生产端**
    - 开启 Confirm 机制， 通过 “确认机制 + 重试 + 本地事务” 保证消息必发
2. **Broker**
    - 持久化 Exchange / Queue / Message，服务端需配置 “持久化 + 高可用集群”，避免单机宕机或重启导致消息丢失
3. **消费端**
    - 手动 ACK，手动确认 + 幂等性处理 + 失败重试

---

### 5、为什么会出现重复消费？
重复消费的本质是「消息的 ACK 确认机制异常」，常见场景：
- **消费者 ACK 丢失**：消费者处理完消息后，向 Broker 发送 ACK 时网络波动，Broker 未收到 ACK，认为消息未消费，重启后重发消息；
- **生产者重试**：生产者发送消息后未收到 Broker 确认，触发重试，导致多条相同消息进入队列；
- **队列镜像 / 集群同步**：RabbitMQ 集群镜像队列同步异常，导致消息副本被多次投递；
- **消费者重启**：消费者处理消息过程中宕机（如 OOM、进程被杀），Broker 重新分发未确认的消息。

### 6. 如何避免消息被重复消费？
- 核心解决方案是让消费逻辑具备**幂等性**—— 即「多次消费同一消息，结果与单次消费完全一致」

#### 方案 1：基于「唯一消息 ID + 分布式锁 / Redis 去重」（最通用）
**核心逻辑**：
1.  生产者发送消息时，为每条消息生成唯一 ID（如 UUID、雪花算法 ID），放入消息的 `messageId` 属性；
2.  消费者接收消息后，先通过 Redis 的 `SETNX`（SET if Not Exists）命令校验该 ID 是否已处理：
   - 若 `SETNX` 成功（未处理）：执行消费逻辑，消费完成后保留该 ID（设置过期时间，避免 Redis 堆积）；
   - 若 `SETNX` 失败（已处理）：直接返回成功，不执行业务逻辑。

**优势**：实现简单、性能高（Redis 操作是内存级），适配 90% 以上场景；
**适用场景**：非金融级、高并发的通用业务（如订单通知、短信发送、数据同步）。

#### 方案 2：基于「数据库唯一键约束」（金融级强一致性）
**核心逻辑**：
1.  将消息的唯一 ID（或业务唯一标识，如订单 ID）作为数据库表的「唯一索引 / 主键」；
2.  消费者处理消息时，尝试将业务数据插入数据库：
   - 若插入成功（唯一键无冲突）：执行后续业务逻辑；
   - 若插入失败（唯一键冲突）：说明消息已处理，直接返回成功。

**优势**：依托数据库事务和唯一约束，实现「消费 + 数据写入」的原子性，适合金融级场景；
**适用场景**：支付、转账、订单创建等强一致性业务。

#### 方案 3：基于「本地缓存 / 内存标记」（单机场景）
**核心逻辑**：
1.  消费者进程内维护一个「已处理消息 ID 缓存」（如 Guava Cache、ConcurrentHashMap）；
2.  消费前校验缓存中是否存在该消息 ID：存在则跳过，不存在则处理并标记。

**优势**：无需外部存储，性能最高；
**局限性**：仅适用于「单实例消费者」场景，消费者重启后缓存丢失，可能重复消费；
**适用场景**：单机部署、非核心业务（如日志收集）。

#### 方案 4：基于「消息状态机」（复杂业务）
**核心逻辑**：
1.  为业务设计「状态机」（如订单状态：待支付→支付中→已支付→已完成）；
2.  消费消息时，先校验当前业务状态：若状态已达到目标（如已支付），则跳过；若未达到，则执行状态变更。

**优势**：无需额外存储，依托业务自身状态实现幂等；
**适用场景**：有明确状态流转的业务（如订单、工单、支付）。

#### 总结
| 方案 | 实现成本 | 性能 | 一致性 | 适用场景 | 局限性 |
|------|----------|------|--------|----------|--------|
| Redis SETNX 去重 | 低 | 高 | 最终一致 | 通用业务、高并发 | 依赖 Redis 可用性 |
| 数据库唯一键 | 中 | 中 | 强一致 | 金融级、支付 / 订单等核心业务 | 数据库性能瓶颈 |
| 本地缓存 | 极低 | 极高 | 单机一致 | 单机部署、非核心业务 | 集群 / 重启后失效 |
| 消息状态机 | 中 | 中 | 强一致 | 有状态流转的业务 | 仅适配特定业务 |

---


### 7. 什么是死信队列（DLQ）？什么时候用？

死信队列（Dead-Letter Queue） 不是一个独立的队列类型，而是消息队列的一种 **“异常消息处理机制”**：
当消息在正常队列中满足特定条件无法被消费时，会被自动转发到一个专门的队列，这个专门存放 **“死信”** 的队列就叫死信队列。

正常队列称为 **“源队列”**，死信队列是源队列的附属队列，需要单独配置。

#### 消息成为 “死信” 的 3 个核心条件
不同消息中间件（RabbitMQ、RocketMQ、Kafka）的规则基本一致，满足以下任一条件，消息会变成死信：

| 条件 | 具体说明 |
|------|----------|
| 消息被拒绝消费 | 消费者明确拒绝消费这条消息（如 basic.reject/basic.nack），且设置 requeue=false（不重新入队） |
| 消息过期 | 消息设置了存活时间（TTL），在源队列中超过时间仍未被消费 |
| 队列达到最大长度 | 源队列配置了最大容量，队列满了之后，新消息会挤掉旧消息，被挤掉的旧消息会进入死信队列 |

#### 死信队列的核心特性
- **隔离性**：死信和正常消息隔离，不会污染正常业务的消息队列；
- **可追溯性**：死信消息会保留原消息的所有信息（如内容、投递次数、过期时间），便于排查问题；
- **可重试性**：可以通过消费死信队列的消息，做人工干预重试或定时重试。

#### 典型应用：
- 消费失败兜底：避免消息丢失，便于问题排查 
- 实现延迟队列（RabbitMQ 无原生延迟队列）
- 处理队列溢出消息：保护核心服务
> 超时未支付订单  
> 失败消息补偿

---

### 8. RabbitMQ 如何实现延迟消息？

- TTL + DLX
- 插件（x-delayed-message）

---

### 9. MQ 如何保证顺序性？
MQ 保证消息顺序性的核心是「让需要有序的消息，按生产顺序被消费」—— 本质是**避免「多生产者乱序写入」「多消费者并行消费」「消息重试 / 重发打乱顺序」**

- 同一业务键 → 同一队列
- 单线程消费
- 不强求全局顺序

#### 一、先明确：什么场景需要保证消息顺序？
并非所有场景都需要顺序性，只有**「业务操作有依赖关系」**时才需要，比如：
- 订单状态流转：创建订单→支付订单→发货订单→完成订单（必须按此顺序消费）；
- 商品操作：库存增加→库存扣减→库存冻结（顺序错乱会导致库存数据错误）；
- 日志同步：用户操作日志需按时间顺序写入数仓（乱序会导致日志时序错误）。

**核心结论**：无需为所有消息保证顺序，仅对「同一业务维度」的消息（如同一订单、同一商品）保证顺序即可。

#### 二、保证消息顺序性的通用原则
无论哪种 MQ，保证顺序的核心是 3 点：
1.  **生产端有序**：同一业务维度的消息，由单个生产者线程写入（或写入同一分区 / 队列），避免多线程乱序；
2.  **存储端有序**：MQ 服务端保证同一分区 / 队列内的消息按生产顺序存储（Kafka 分区、RabbitMQ 单队列天然有序）；
3.  **消费端有序**：同一分区 / 队列仅由单个消费者线程消费，避免多线程并行消费打乱顺序。

#### 三、RabbitMQ 保证消息顺序性的方案
RabbitMQ 本身是**「队列级有序」**（单队列内消息 FIFO），但多队列 / 多消费者会破坏顺序，核心方案是「单队列 + 单消费者」+ 业务分区。

##### 方案 1：基础方案 —— 单队列 + 单消费者（简单但性能低）
**核心逻辑**：
- 生产者：将同一业务维度的消息（如同一订单）发送到「同一个队列」；
- 消费者：仅启动「单个线程」监听该队列，按顺序消费消息。

**优势**：实现最简单，完全依赖 RabbitMQ 队列的 FIFO 特性；
**劣势**：单消费者线程性能瓶颈，无法横向扩容，仅适用于低并发场景。

##### 方案 2：进阶方案 —— 按业务维度分区（高并发场景）
**核心逻辑**：
1.  按「业务维度」（如 orderId 哈希）创建多个队列（如 8 个队列）；
2.  生产者：同一 orderId 的消息，通过哈希算法路由到「同一个队列」；
3.  消费者：每个队列对应一个单线程消费者，队列间并行，队列内串行。

**优势**：兼顾「顺序性」和「并发性」，可通过增加队列数扩容；
**劣势**：需提前规划队列数，哈希不均可能导致队列负载失衡。

#### 四、关键避坑点（所有 MQ 通用）
- **消息重试会打乱顺序**：若消费失败后重新入队，重试的消息会被放到队列尾部，导致顺序错乱 —— 解决方案：消费失败不重新入队，直接进入死信队列人工处理；
- **生产者多线程乱序**：同一 Key 的消息若由多个生产者线程发送，可能因网络延迟导致乱序 —— 解决方案：同一 Key 的消息由单个生产者线程发送，或使用同步发送；
- **分区数不可动态调整**：Kafka 分区数、RabbitMQ 队列数一旦确定，动态调整会导致哈希规则变化，破坏顺序 —— 解决方案：提前规划足够的分区 / 队列数；
- **避免批量消费 / 批量提交**：批量消费会一次性拉取多条消息，若部分消费失败，批量提交会导致未消费的消息被标记为已消费，破坏顺序 —— 解决方案：单条消费、单条提交。

---









