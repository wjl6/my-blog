---
title: "003-ElasticSearch.md"
date: 2025-12-27 18:34:01
tags: []
---

### 1. 为什么要用 ES？不用 MySQL 行不行？
ES（Elasticsearch）和 MySQL 定位完全不同，**ES 专为全文检索、数据分析设计，MySQL 专为关系型数据存储、事务性操作设计**

ES （倒排索引）：
- **倒排索引是全文检索引擎的核心数据结构**，它以 “关键词” 为中心，记录每个关键词出现在哪些文档（或记录）中，以及出现的位置、频次等信息
- 

适合场景：
- 全文检索
- 大数据量聚合分析
- 地理位置检索
- 日志检索分析

MySQL（B+树索引）：
- 简单精确查询
- 事务性操作
- 小数据量简单模糊查询

> 正排索引：书的目录 → 章节 → 章节内的内容关键词  
> 倒排索引：书的索引表 → 关键词 → 该关键词出现在哪些章节、哪些页码

| 结构 | 作用 |
|------|------|
| 词典（Dictionary） | 存储所有去重后的关键词（Term），是倒排索引的 “索引的索引”，通常用哈希表或 B + 树存储，用于快速查找关键词。 |
| 倒排列表（Posting List） | 每个关键词对应一个倒排列表，存储该关键词出现的文档 ID 集合，以及可选的附加信息（如出现位置、频次、权重）。 |

> B + 树索引是**关系型数据库和有序存储引擎的核心索引结构**，它是一种 **平衡多路查找树**，**所有数据都存储在叶子节点，且叶子节点按索引键值有序排列，并通过双向链表连接**


👉 **ES ≠ 数据库替代品**

---

### 2. ES 的核心概念？

| ES 核心概念 | MySQL 对应概念 | 核心作用 | 关键说明 |
|-------------|----------------|----------|----------|
| Index（索引） | Database（数据库） | 存储一类相似结构的文档 | 1. 索引是 ES 中最高级别的数据组织单位，一个索引对应一类业务数据（如 product_index 存储商品、order_index 存储订单）；<br>2. 索引名必须小写，不能包含特殊字符；<br>3. 索引会被分片存储到多个节点，实现分布式扩容。 |
| Type（类型） | Table（表） | 索引内的文档分类（ES 7.x 已废弃） | 1. ES 5.x/6.x 中，一个索引可以包含多个 Type（如 user_index 包含 vip_user 和 normal_user 两个 Type）；<br>2. ES 7.x 及以后，Type 被废弃，一个索引只能存储一类文档，Type 默认为 _doc；<br>3. 废弃原因：不同 Type 共用同一索引的分片，会导致资源竞争和数据混乱。 |
| Document（文档） | Row（行） | ES 的最小数据单元 | 1. 文档是 JSON 格式的数据，每个文档有唯一 ID（手动指定或 ES 自动生成）；<br>2. 文档属于某个索引，相当于 MySQL 表中的一行数据；<br>3. 文档是无模式（schema-less） 的，允许同一索引下的文档有不同字段（但实际开发中会尽量保持字段一致）。 |
| Field（字段） | Column（列） | 文档的属性 | 1. 每个字段有对应的数据类型（如 text 文本、keyword 关键字、integer 整数、date 日期）；<br>2. 字段类型决定了该字段能否被检索、如何被检索：<br>- text 类型：会被分词（如 “华为手机” 拆分为 “华为”“手机”），支持全文检索；<br>- keyword 类型：不会被分词，支持精确匹配和聚合分析。 |
| Mapping（映射） | Table Schema（表结构） | 定义文档的字段类型、分词器等属性 | 1. Mapping 相当于 MySQL 的表结构定义，明确每个字段的数据类型和检索规则；<br>2. ES 支持动态映射：写入文档时自动推断字段类型（如数字→long，字符串→text+keyword）；<br>3. 生产环境建议手动创建 Mapping，避免动态映射推断错误（如把 “100” 识别为 long 而非 keyword）。 |


---

### 3. ES 为什么快？
- 倒排索引为核心的存储结构
- 分布式并行计算
- 检索流程深度优化（利用内存缓存了热数据的倒排索引和文档数据）

---

### 4. 倒排索引是什么？
> 倒排索引：书的索引表 → 关键词 → 该关键词出现在哪些章节、哪些页码

| 结构 | 作用 |
|------|------|
| 词典（Dictionary） | 存储所有去重后的关键词（Term），是倒排索引的 “索引的索引”，通常用哈希表或 B + 树存储，用于快速查找关键词。 |
| 倒排列表（Posting List） | 每个关键词对应一个倒排列表，存储该关键词出现的文档 ID 集合，以及可选的附加信息（如出现位置、频次、权重）。 |

- 词 → 文档列表
- 非逐行扫描
- 适合全文搜索

---

### 5. ES 分片与副本的作用？
分片（Shard）和副本（Replica）是 Elasticsearch 实现 **分布式存储、高可用、高并发检索** 的两大核心机制

#### （一） 分片（Shard）的作用
分片是 ES 将一个索引的数据 **水平拆分** 后的最小存储单元，每个分片本质上是一个独立的 Lucene 索引，拥有完整的倒排索引结构。

##### 1. 核心作用 1：突破单节点硬件限制，实现水平扩容
ES 单个节点的内存、磁盘容量有限，无法存储海量数据（比如亿级文档）。
通过分片，一个索引的数据被拆分成多个部分，分布在不同的节点上。
- 示例：一个 100GB 的索引拆分为 5 个分片，每个分片约 20GB，可分别部署在 5 个节点上，避免单节点磁盘过载。
- 关键特性：索引创建后，**主分片数量不可修改**（副本数量可动态调整），因此创建索引时需提前规划分片数（参考：单分片大小建议 20~50GB）。

##### 2. 核心作用 2：实现并行检索，提升查询性能
当发起检索请求时，ES 的协调节点会将请求 **并行分发** 到该索引的所有分片上。
每个分片独立执行查询，然后将结果返回给协调节点，协调节点合并结果后返回给客户端。
- 性能优势：理论上，分片数越多，并行度越高，检索速度越快（需注意：分片数过多会增加调度开销，需合理规划）。

#### （二） 副本（Replica）的作用
副本是主分片的 **冗余备份**，一个主分片可以对应多个副本分片，副本和主分片的数据完全一致。

##### 1. 核心作用 1：保证数据高可用，避免单点故障
当主分片所在的节点宕机时，ES 集群会自动将该主分片的某个副本分片 **提升为主分片**，继续提供服务，数据不会丢失。
- 可用性保障：副本数量越多，高可用能力越强（比如 1 个主分片 + 2 个副本，即使两个节点宕机，仍有 1 个副本可用）。

##### 2. 核心作用 2：分担检索压力，提升并发读性能
副本分片和主分片一样，拥有完整的索引数据，支持检索请求。
ES 会将检索请求均匀分发到主分片和所有副本分片上，大幅提升系统的并发读能力。
- 示例：1 个主分片 + 1 个副本，检索并发量理论上可提升 1 倍；1 个主分片 + 2 个副本，并发量可提升 2 倍。

##### 3. 副本的关键特性
- 副本分片 **不能和对应的主分片部署在同一个节点**（否则节点宕机时，主分片和副本同时丢失，失去备份意义）。
- 副本数量可 **动态调整**（无需重建索引），生产环境可根据业务压力随时扩容 / 缩容。

#### 总结
| 机制 | 核心作用 | 关键价值 |
|------|----------|----------|
| 分片（Shard） | 1. 水平拆分数据，突破单节点限制<br>2. 并行检索，提升查询速度 | 支撑海量数据存储，提升检索性能 |
| 副本（Replica） | 1. 冗余备份，保证数据高可用<br>2. 分担读压力，提升并发能力 | 避免数据丢失，支撑高并发检索 |
---

### 6. ES 写入流程？

- 客户端发送写入请求到协调节点
- 协调节点根据路由规则（默认按文档 ID 哈希），将请求路由到对应的主分片
- 主分片写入数据并同步到其所有副本分片
- 所有副本分片写入成功后，主分片返回成功响应给客户端

---

### 7. ES 数据检索流程？
- 客户端发送检索请求到协调节点
- 协调节点将请求分发到该索引的 **所有主分片和副本分片**（或随机选择部分分片，取决于查询类型）
- 各分片并行执行查询，返回匹配的文档 ID 和评分
- 协调节点合并所有分片的结果，按评分排序后，获取前 N 条文档的完整数据，返回给客户端
---

### 8. ES 如何保证数据不丢？

- **副本冗余**：主分片 + 副本分片多副本存储，节点宕机不丢数据
- **translog 持久化**：内存数据写入时同步刷盘，宕机后可恢复未持久化数据
- 故障自动转移：节点宕机后自动提升副本为主分片，快速恢复服务
- **一致性控制**：写入时校验分片可用性，从源头保证写入可靠性

---

### 9. ES 查询优化手段？

- 避免深度分页
- 合理分片数量
- 关闭无用字段索引
- 利用缓存：**filter 子句**、文件系统缓存能大幅提升性能；
- 索引层优先：好的索引设计是性能的基础，比优化查询语句更重要；
- 避免全扫描：任何导致全索引 / 全分片扫描的查询都是性能杀手；
- 合理分配资源：内存、SSD 是 ES 性能的关键硬件保障。
---

### 10. ES 和 Mysql中数据如何保持一致性？

- 强一致性需求 → 选择 同步双写
- 高性能、高并发需求 → 选择 Canal 异步同步
- 数据一致性兜底 → 搭配 定时全量同步
- 本地消息表（最终一致性）
---

### 11. ES 深度分页问题如何解决？
ES 的深度分页（Deep Pagination）是指在分页查询中，请求的页码过大（如第 1000 页、第 10000 页）时，出现**查询性能急剧下降、甚至返回报错（如 MaxResultWindowExceededException）的问题**

ES 最基础的分页方式 from + size 的执行逻辑，这是理解深度分页问题的前提。

```json
# ES DSL 示例：查询第 10 页，每页 10 条数据（from 从 0 开始计数）
GET /index_name/_search
{
  "from": 90,  # 跳过前 90 条数据
  "size": 10,  # 返回 10 条数据
  "query": {
    "match_all": {}
  }
}
```

#### 深度分页问题的核心成因
当 from 值过大（即页码过深）时，上述执行流程会暴露出两个致命问题，这就是深度分页的根源：
- 数据传输与内存开销爆炸
   - 随着 from 值增大，每个分片需要返回给协调节点的数据量（from + size）会急剧增加，大量数据在网络中传输，占用极高的网络带宽；
   - 协调节点需要收集所有分片的大量数据，进行全局排序和筛选，这会占用协调节点大量的内存和 CPU 资源，当数据量超出节点承载能力时，会导致查询超时或节点宕机。
- ES 内置的安全限制（max_result_window）
   - ES 为了保护集群稳定性，默认设置了 max_result_window 参数（默认值为 10000），即 from + size 的总和不能超过 10000；
   - 当尝试查询 from=9999、size=2 时，from + size = 10001，超出默认限制，会直接抛出 MaxResultWindowExceededException 异常，拒绝查询请求。
- 直观举例
   - 查询第 10 页（from=90、size=10）：每个分片返回 100 条，5 个分片共返回 500 条，协调节点排序后取 10 条；
   - 查询第 1000 页（from=9990、size=10）：每个分片返回 10000 条，5 个分片共返回 50000 条，协调节点需要对 5 万条数据排序后取 10 条；
   - 查询第 10000 页（from=99990、size=10）：不仅超出 max_result_window 限制报错，即使修改限制，也会导致集群资源耗尽。
- **核心总结**：from + size 分页是「拉取所有前置数据再筛选」，深度分页时是「用海量资源换少量结果」，完全不具备可扩展性。

#### 深度分页问题的 3 种核心解决方案

**方案 1：Scroll API（滚动分页）—— 适合批量导出 / 数据同步（非实时查询）**

Scroll API 是 ES 专门用于 ** 批量获取大量数据（甚至全量数据）** 的方案，它不支持随机分页（无法直接跳转到第 N 页），但可以高效地「向后翻页」获取全量数据，适合数据导出、批量更新、离线统计等非实时场景。


1. 实现原理
   - 创建快照：首次发起 Scroll 查询时，ES 会创建一个当前索引数据的「时间点快照（Snapshot）」，后续的滚动查询都基于这个快照，不受后续数据新增 / 修改 / 删除的影响（保证数据一致性）；
   - 保存滚动上下文：ES 会生成一个「滚动 ID（scroll_id）」，用于保存当前的查询上下文（包括快照、查询条件、排序规则等），默认保留 5 分钟；
   - 分批滚动获取：后续每次查询都携带 scroll_id，ES 会从上次查询的末尾开始，返回下一批数据，直到返回数据为空，说明已获取全量数据；
   - 清理上下文：查询完成后，建议手动清理 scroll_id，释放 ES 集群资源。

3. 优缺点
   - 优点：
     - 高效稳定，支持全量数据批量获取，不会因数据量过大导致性能爆炸；
     - 基于快照查询，数据一致性有保障；
     - 不占用 max_result_window 限制，可突破 10000 条数据的限制。
   - 缺点：
     - 不支持随机分页（无法直接跳转到第 N 页），仅支持「向后翻页」；
     - 快照数据不实时，无法获取查询期间的新增 / 修改 / 删除数据；
     - 占用 ES 集群资源（快照和上下文），若未及时清理，会影响集群性能；
     - 不适合用户交互场景（如前端分页器跳转页码）。

**方案 2：Search After（基于排序值分页）—— 适合实时分页 / 用户交互场景**

Search After 是 ES 5.0 之后推出的分页方案，它基于上一页最后一条数据的排序字段值，作为下一页查询的「锚点」，实现高效的向后分页，支持实时数据查询，适合用户交互场景（如前端列表分页、移动端下拉加载更多）。
1. 实现原理
   - 依赖唯一排序：使用 Search After 必须指定一个「全局唯一的排序规则」（通常是「业务字段 + _id」，避免排序冲突导致数据重复或遗漏）；
   - 锚点查询：首次查询（第 1 页）无需 search_after，直接返回数据；后续查询（第 N 页）携带上一页最后一条数据的排序字段值，ES 会从该「锚点」之后开始查询，返回下一批数据；
   - 分布式高效查询：每个分片只需从锚点之后返回 size 条数据，无需返回前置数据，协调节点只需汇总各分片的 size 条数据，无需全局排序大量数据，性能远高于 from + size；
   - 实时性保障：不创建快照，每次查询都基于当前索引的实时数据，支持获取最新的数据变更。

2. 优缺点
   - 优点：
     - 性能高效，支持深度分页，无 max_result_window 限制，适合百万级数据分页；
     - 实时性好，基于当前实时数据查询，支持数据新增 / 修改 / 删除；
     - 资源开销小，每个分片仅返回 size 条数据，协调节点无需大量排序；
     - 适合用户交互场景（如下拉加载更多、前端分页器向后翻页）。
   - 缺点：
     - 不支持随机分页（无法直接跳转到第 N 页，只能从当前页向后翻）；
     - 依赖唯一排序规则，若排序字段变更，会导致分页错乱；
     - 无法向前翻页（如从第 5 页回到第 4 页），除非缓存每一页的锚点值；
     - 若锚点数据被删除或修改，可能导致下一页数据重复或遗漏。

**方案 3：PIT（Point in Time，时间点快照）+ Search After —— 适合需要一致性的实时分页**
PIT 是 ES 7.10 之后推出的特性，它结合了 Scroll API 的「数据一致性」和 Search After 的「高效实时分页」，解决了 Search After 实时查询的数据不一致问题，适合既需要深度分页、又需要数据一致性的场景（如金融数据查询、报表生成）。
1. 实现原理
   - 创建时间点快照（PIT）：首次查询前，创建一个索引的 PIT 快照，保留当前索引的数据状态，返回一个 pit_id；
   - PIT + Search After 分页：后续使用 Search After 分页时，携带 pit_id，ES 会基于 PIT 快照进行查询，保证分页过程中数据的一致性（不受后续数据变更影响）；
   - 延长快照有效期：PIT 快照默认保留 5 分钟，可在查询过程中延长有效期；
   - 清理 PIT 快照：查询完成后，手动清理 pit_id，释放集群资源。
2. 优缺点
     - 优点：
       - 兼顾高效性（Search After）和数据一致性（PIT 快照）；
       - 支持深度分页，无 max_result_window 限制；
       - 可延长快照有效期，适合长时间的分页查询。
     - 缺点：
       - 不支持随机分页，仅支持向后翻页；
       - 占用集群资源（PIT 快照），需及时清理；
       - ES 版本要求较高（≥7.10），升级成本可能较高。

#### 对比
| 解决方案          | 适用场景                                     | 核心优势                                     | 核心局限                                     |
|-------------------|----------------------------------------------|----------------------------------------------|----------------------------------------------|
| Scroll API        | 批量导出、数据同步、离线统计、全量数据查询     | 高效稳定、支持全量数据、数据一致性好         | 不支持随机分页、快照不实时、占用资源多       |
| Search After      | 前端分页、移动端下拉加载更多、实时数据查询     | 性能高效、实时性好、资源开销小               | 不支持随机分页、无法向前翻页、依赖唯一排序   |
| PIT + Search After | 金融数据查询、报表生成、需要一致性的实时分页   | 兼顾高效性和数据一致性、支持深度分页         | 版本要求高、不支持随机分页、占用资源         |
| 原生 from + size  | 浅分页（页码 ≤ 100）、简单查询                 | 用法简单、支持随机分页                       | 深度分页性能爆炸、受 max_result_window 限制   |

---






